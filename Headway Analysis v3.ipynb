{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headway Analysis v3\n",
    "## <i>f.k.a. LA Metro Checker</i>\n",
    "### Another try at getting this right\n",
    "Trying new ways in Pandas to figure out which stops are high-quality transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, time, datetime, csv, os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## static bits\n",
    "These cells define functions and variables that will not change over the course of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def minSinceMidnight(t):\n",
    "    if type(t) == str:\n",
    "        tt = t.split(':')\n",
    "        msm = (int(tt[0])*60) + int(tt[1]) + (int(tt[2])/60)\n",
    "    else:\n",
    "        msm = t\n",
    "    return msm\n",
    "\n",
    "## REWROTE on 9/20 TO DEAL WITH DUPLICATE TIMES\n",
    "\n",
    "def interpolator(trip):\n",
    "    \n",
    "    lsst = list(stop_times[stop_times['trip_id'] == trip]['arrival_time'])\n",
    "    lsst = [minSinceMidnight(x) for x in lsst]\n",
    "    \n",
    "    last_scheduled_time = lsst[0]\n",
    "    lst_index = 0\n",
    "    \n",
    "    values = [last_scheduled_time]\n",
    "    \n",
    "    for x in range(1,len(lsst)):\n",
    "        #print(x)\n",
    "        if pd.isnull(lsst[x]) == False:\n",
    "            #idx = lsst.index(x)\n",
    "            #print(idx)\n",
    "            yy = list(np.linspace(last_scheduled_time, lsst[x], num=(x-lst_index+1)))\n",
    "\n",
    "            values += yy[1:]\n",
    "            last_scheduled_time = lsst[x]\n",
    "            lst_index = x\n",
    "        else:\n",
    "            pass\n",
    "    return values # returns linear interpolation of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unchanging data\n",
    "\n",
    "# days to evaluate\n",
    "weekday = \"20181101\"\n",
    "saturday = \"20181103\"\n",
    "sunday = \"20181104\"\n",
    "\n",
    "days_of_week = {0:\"monday\", 1:\"tuesday\", 2:\"wednesday\", 3:\"thursday\", 4:\"friday\", 5:\"saturday\", 6:\"sunday\"}\n",
    "\n",
    "# modes\n",
    "bus_types = [3]\n",
    "rail_types = [0,1,2]\n",
    "ferry_types = [4]\n",
    "\n",
    "# queries to filter by various time criteria\n",
    "# strings for pd.DF.query\n",
    "\n",
    "am_peak_query = \"interpolated >= 360 and interpolated <= 600\"\n",
    "pm_peak_query = \"interpolated >= 900 and interpolated <= 1140\"\n",
    "weekday_range_query = \"interpolated >= 360 and interpolated <= 1320\"\n",
    "saturday_range_query = \"interpolated >= 480 and interpolated <= 1320\"\n",
    "sunday_range_query = \"interpolated >= 480 and interpolated <= 1320\"\n",
    "\n",
    "# defines the schema for the dict object holding headways\n",
    "\n",
    "dataHolderSpec = {\n",
    "                  \"name\":'',\n",
    "                  \"longitude\":np.NaN,\n",
    "                  \"latitude\":np.NaN,\n",
    "                0: {\n",
    "                    \"served_by\": [],\n",
    "                    \"AM Peak\": np.NaN,\n",
    "                    \"PM Peak\": np.NaN,\n",
    "                    \"Weekdays\": np.NaN,\n",
    "                    \"Saturday\": np.NaN,\n",
    "                    \"Sunday\": np.NaN\n",
    "                     },\n",
    "                 1: {\n",
    "                    \"served_by\": [],\n",
    "                    \"AM Peak\": np.NaN,\n",
    "                    \"PM Peak\": np.NaN,\n",
    "                    \"Weekdays\": np.NaN,\n",
    "                    \"Saturday\": np.NaN,\n",
    "                    \"Sunday\": np.NaN\n",
    "                     }\n",
    "                 }\n",
    "\n",
    "\n",
    "# starting index\n",
    "start_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define agencies\n",
    "These cells offer a few different ways to define the agency to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_agencies = list(os.walk('gtfs'))[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency = \"gtfs/la-metro--184/\"\n",
    "# agency = \"gtfs/sfmta--60/\"\n",
    "path = agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_agency = list_of_agencies[np.random.randint(len(list_of_agencies))]\n",
    "rand_agency\n",
    "\n",
    "path = \"gtfs/\" + rand_agency + \"/\"\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GTFS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_name = pd.read_csv(path + 'agency.txt')['agency_name'][0]\n",
    "agency_name = agency_name.replace(\"/\",\"-\")\n",
    "print(agency_name)\n",
    "\n",
    "trips = pd.read_csv(path + 'trips.txt')\n",
    "print(len(trips), \"trips\")\n",
    "\n",
    "routes = pd.read_csv(path + 'routes.txt')\n",
    "print(len(routes), \"routes\")\n",
    "\n",
    "stops = pd.read_csv(path + 'stops.txt')\n",
    "print(len(stops), \"stops\")\n",
    "\n",
    "stop_times = pd.read_csv(path + 'stop_times.txt')\n",
    "print(len(stop_times), \"stop times\")\n",
    "\n",
    "try:\n",
    "    calendar = pd.read_csv(path + \"calendar.txt\")\n",
    "    print(len(calendar), \"schedules\")\n",
    "    calend = True\n",
    "except FileNotFoundError:\n",
    "    calend = False\n",
    "\n",
    "calendar_dates = pd.read_csv(path + \"calendar_dates.txt\")\n",
    "print(len(calendar_dates), \"exception dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the schedules (service_ids) to be used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary object with exceptions dates for different types of service\n",
    "\n",
    "exceptions = {}\n",
    "\n",
    "for x in range(len(calendar_dates)):\n",
    "    exception_date = str(calendar_dates['date'][x])\n",
    "    exception_service_id = calendar_dates['service_id'][x]\n",
    "    exception_type = calendar_dates['exception_type'][x]\n",
    "\n",
    "    if exception_date not in exceptions:\n",
    "        exceptions[exception_date] = {1:[],2:[]}\n",
    "        exceptions[exception_date][exception_type].append(exception_service_id)\n",
    "    else:\n",
    "        exceptions[exception_date][exception_type].append(exception_service_id)\n",
    "\n",
    "# GENERATES service_ids IN USE ON SPECIFIED DAY OF WEEK\n",
    "# ALSO ENSURES THAT SCHEDULES ARE ACTIVE DURING SPECIFIED TIME FRAME\n",
    "\n",
    "weekday_day = days_of_week[datetime.datetime(int(weekday[:4]), int(weekday[4:6]), int(weekday[6:])).weekday()]\n",
    "saturday_day = days_of_week[datetime.datetime(int(saturday[:4]), int(saturday[4:6]), int(saturday[6:])).weekday()]\n",
    "sunday_day = days_of_week[datetime.datetime(int(sunday[:4]), int(sunday[4:6]), int(sunday[6:])).weekday()]\n",
    "\n",
    "# this if-else statement checks to make sure that calendar.txt file is up to date\n",
    "# if none of the service_id are currently active, we take them anyway\n",
    "# otherwise, we filter out any inactive service_id\n",
    "\n",
    "if len([x for x in list(calendar['end_date']) if x > np.min([int(weekday), int(saturday), int(sunday)])]) == 0:\n",
    "    weekday_query = \"(%s == 1) & (%s >= start_date)\" % (weekday_day, weekday)\n",
    "    saturday_query = \"(%s == 1) & (%s >= start_date)\" % (saturday_day, saturday)\n",
    "    sunday_query = \"(%s == 1) & (%s >= start_date)\" % (sunday_day, sunday)\n",
    "else:\n",
    "    weekday_query = \"(%s == 1) & (%s >= start_date) & (%s <= end_date)\" % (weekday_day, weekday, weekday)\n",
    "    saturday_query = \"(%s == 1) & (%s >= start_date) & (%s <= end_date)\" % (saturday_day, saturday, saturday)\n",
    "    sunday_query = \"(%s == 1) & (%s >= start_date) & (%s <= end_date)\" % (sunday_day, sunday, sunday)\n",
    "\n",
    "# LISTS OF SERVICE_IDs FOR USE IN ANALYSIS\n",
    "if calend == True:\n",
    "    weekday_service = list(calendar.query(weekday_query)['service_id'])\n",
    "    saturday_service = list(calendar.query(saturday_query)['service_id'])\n",
    "    sunday_service = list(calendar.query(sunday_query)['service_id'])\n",
    "elif calend == False:\n",
    "    weekday_service = exceptions[weekday][1]\n",
    "    saturday_service = exceptions[saturday][1]\n",
    "    sunday_service = exceptions[sunday][1]\n",
    "# create dictionary object to hold information about stops\n",
    "# dictionary will be used for quick access\n",
    "\n",
    "if len(weekday_service) == 0 or len(saturday_service) == 0 or len(sunday_service) == 0:\n",
    "    print(agency.upper(), \"SERVICE ISSUE -- PLEASE FIX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge route, trip, and stop_time data together to produce a comprehensive dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the fully-formed stops file\n",
    "\n",
    "trip_info = trips[[\"route_id\", \"service_id\", \"trip_id\", \"direction_id\"]]\n",
    "route_info = routes[['route_id', 'route_type']]\n",
    "\n",
    "trip_route_merged = trip_info.merge(route_info, on=\"route_id\")\n",
    "\n",
    "# reorder columns\n",
    "trip_route_merged = trip_route_merged[[\"trip_id\", \"route_id\", \"service_id\", \"direction_id\", \"route_type\"]]\n",
    "\n",
    "if trips['trip_id'].dtype == object:\n",
    "\n",
    "    # create a string version of trip_id\n",
    "    stop_times['trip_id_str'] = stop_times['trip_id'].astype(\"str\")\n",
    "\n",
    "    # merge trip info onto stop_times\n",
    "    stop_times_merged = stop_times[[\"trip_id_str\", 'arrival_time', 'stop_id']].merge(trip_route_merged, right_on=\"trip_id\", left_on=\"trip_id_str\", how='left')\n",
    "\n",
    "else:\n",
    "    \n",
    "    stop_times_merged = stop_times[[\"trip_id\", 'arrival_time', 'stop_id']].merge(trip_route_merged, right_on=\"trip_id\", left_on=\"trip_id\", how='left')\n",
    "\n",
    "# calculate a interpolated (float) time for future analysis\n",
    "\n",
    "\n",
    "if (sum(pd.isnull(stop_times_merged['arrival_time']))/len(stop_times_merged)) > 0.05:\n",
    "    agency_trips = list(stop_times.drop_duplicates('trip_id')['trip_id'])\n",
    "    allInterpolatedTimes = []\n",
    "    for trip in agency_trips:\n",
    "        allInterpolatedTimes += interpolator(trip)\n",
    "    stop_times_merged['interpolated'] = allInterpolatedTimes\n",
    "    print(\"INTERP-O-LATED\")\n",
    "else:\n",
    "    stop_times_merged['interpolated'] = [minSinceMidnight(x) for x in stop_times_merged['arrival_time']]\n",
    "\n",
    "stop_times_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump all rail and ferry stops into their own CSVs. Remove rail and ferry stops from the <i>stop_times_merged</i> dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rail_times_merged = stop_times_merged.query(\"route_type in [0,1,2]\")\n",
    "\n",
    "if len(rail_times_merged) > 0:\n",
    "    rail_stops = pd.DataFrame(rail_times_merged['stop_id'].unique(), columns=['stop_id'])\n",
    "    rail_stops = rail_stops.merge(stops[['stop_id', 'stop_name', 'stop_lon', 'stop_lat']], on=\"stop_id\")\n",
    "    rail_stops.to_csv(\"output/v2/rail/\" + agency_name + \".csv\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "ferry_times_merged = stop_times_merged.query(\"route_type in [4]\")\n",
    "\n",
    "if len(ferry_times_merged) > 0:\n",
    "    ferry_stops = pd.DataFrame(ferry_times_merged['stop_id'].unique(), columns=['stop_id'])\n",
    "    ferry_stops = ferry_stops.merge(stops[['stop_id', 'stop_name', 'stop_lon', 'stop_lat']], on=\"stop_id\")\n",
    "    ferry_stops.to_csv(\"output/v2/ferry/\" + agency_name + \".csv\")\n",
    "else:\n",
    "    pass\n",
    "\n",
    "stop_times_merged = stop_times_merged.query(\"route_type == 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new dataframes for stops for each time period: weekdays, Saturdays, Sundays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEEKDAY\n",
    "\n",
    "if weekday in exceptions:\n",
    "    weekday_stops = [weekday_service.remove(x) for x in exceptions[weekday][2]] + exceptions[weekday][1]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "weekday_stops = stop_times_merged[stop_times_merged['service_id'].isin(weekday_service)]\n",
    "print(weekday_stops.shape)\n",
    "\n",
    "# SATURDAY\n",
    "\n",
    "if saturday in exceptions:\n",
    "    saturday_service = [saturday_service.remove(x) for x in exceptions[saturday][2]] + exceptions[saturday][1]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "saturday_stops = stop_times_merged[stop_times_merged['service_id'].isin(saturday_service)]\n",
    "print(saturday_stops.shape)\n",
    "\n",
    "# SUNDAY\n",
    "\n",
    "if sunday in exceptions:\n",
    "    sunday_service = [sunday_service.remove(x) for x in exceptions[sunday][2]] + exceptions[sunday][1]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "sunday_stops = stop_times_merged[stop_times_merged['service_id'].isin(sunday_service)]\n",
    "print(sunday_stops.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headway analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"output/v2/bus/\" + agency_name + \".csv\"\n",
    "\n",
    "headways = pd.DataFrame(data=stops['stop_id'])\n",
    "\n",
    "minutes = 60 * 4\n",
    "df = weekday_stops\n",
    "\n",
    "queries = [am_peak_query, pm_peak_query, weekday_range_query, saturday_range_query, sunday_range_query]\n",
    "periods = ['am_pk', 'pm_pk', 'wkdy', 'sat', 'sun']\n",
    "minute_ranges = [(600-360), (1140-900), (1320-360), (1320-480), (1320-480)]\n",
    "dfs = [weekday_stops, weekday_stops, weekday_stops, saturday_stops, sunday_stops]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    # conditional parameters\n",
    "    df = dfs[i]\n",
    "    minutes = minute_ranges[i]\n",
    "    query = queries[i]\n",
    "    \n",
    "    for direction in [0,1]:\n",
    "        results = pd.DataFrame(minutes / df[df['direction_id']==direction].query(query)['stop_id'].value_counts())\n",
    "        results.reset_index(inplace=True)\n",
    "        results.rename(columns={\"stop_id\":periods[i]}, inplace=True)\n",
    "        results.rename(columns={\"index\":\"stop_id\"}, inplace=True)\n",
    "\n",
    "\n",
    "        headways = headways.merge(results, on=\"stop_id\", suffixes=[\"_dir0\", \"_dir1\"], how='left')\n",
    "\n",
    "output = stops[[\"stop_id\", \"stop_name\", \"stop_lon\", \"stop_lat\"]].merge(headways, on=\"stop_id\", how=\"outer\")\n",
    "\n",
    "output.to_csv(output_path)\n",
    "\n",
    "# output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agency_name.upper(), \"-- total time:\", finishTime - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evaluate the headway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = pd.read_csv(output_path)\n",
    "# loaded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hqt_filter = \"((am_pk_dir0 <= 15) | (am_pk_dir1 <= 15)) & ((pm_pk_dir0 <= 15) | (pm_pk_dir1 <= 15))\"\n",
    "hqt_filter += \" & ((wkdy_dir0 <= 20) | (wkdy_dir1 <= 20)) & \"\n",
    "hqt_filter += \"((sat_dir0 <= 30) | (sat_dir1 <= 30)) & ((sun_dir0 <= 30) | (sun_dir1 <= 30))\"\n",
    "# hqt_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hqt = loaded.query(hqt_filter)\n",
    "\n",
    "if len(hqt) > 0:\n",
    "    hqt.to_csv(\"output/v2/bus-hqt/\" + agency_name + \" (HQT).csv\")\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_qual = len(hqt) / len(loaded)\n",
    "print(len(hqt), \"of\", len(loaded), \"stops --\", round(pct_qual, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_qual = len(hqt) / len(loaded)\n",
    "print(\"###############\")\n",
    "print(len(hqt), \"of\", len(loaded), \"stops --\", round((pct_qual*100),1), \"%\")\n",
    "print(\"###############\")\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.plot(loaded['stop_lon'], loaded['stop_lat'], 'ok')\n",
    "plt.plot(hqt['stop_lon'], hqt['stop_lat'], 'or')\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend([\"All\", \"HQT\"])\n",
    "plt.title(agency_name)\n",
    "\n",
    "plt.savefig(\"output/v2/img/\" + agency_name + \".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
